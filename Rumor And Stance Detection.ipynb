{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.8 64-bit ('venv')",
   "display_name": "Python 3.6.8 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "f1a579858e6fdecd05cb537e25e5fc54f1c625d793ae6251fb372f9462164bbe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Rumor And Stance Detection\n",
    "This project is a Multi-task Learning of rumor detection and stance detection. Using Pytorch library for the multi-task RNN model and FastText for word embedding.\n",
    "\n",
    "### Basic imports and defines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# GRU params\n",
    "input_length = 400              # the size of each embedded tweet (the size of the input vector)\n",
    "hidden_length_rumors = 500      # the size of the hidden vectors of the rumor detection task GRU\n",
    "hidden_length_stances = 500     # the size of the hidden vectors of the stance detection task GRU\n",
    "hidden_length_shared = 200      # the size of the hidden vectors of the shared GRU\n",
    "output_dim_rumors = 3           # output size for rumor detection (True rumor, False rumor, Unverified)\n",
    "output_dim_stances = 4          # output size for stance classification (Support, Deny, Query, Comment)\n",
    "\n",
    "task_stances_no = 1\n",
    "task_rumors_no = 2"
   ]
  },
  {
   "source": [
    "## Building our model\n",
    "Our model consists of 3 GRU layers:\n",
    "- Task specific layer for Stance detection task\n",
    "- Shared layer for both tasks\n",
    "- Task specific layer for Rumor detection task\n",
    "\n",
    "The inputs are vectors representing tweets after embedding with [*fastText*](https://fasttext.cc/) library."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "Image(filename='model\\\\Multi-task model.PNG', embed=True) "
   ]
  },
  {
   "source": [
    "### Our implementation of GRUCell for the task specific layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCellTaskSpecific(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This class is our implementation of GRUCELL for the task specific layers,\n",
    "    which includes the sharedGRU result in it`s computations.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_length=250, hidden_length=100, hidden_length_shared=100):\n",
    "        super(GRUCellTaskSpecific, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.hidden_length = hidden_length\n",
    "        self.hidden_length_shared = hidden_length_shared\n",
    "\n",
    "        # update gate components\n",
    "        self.linear_w_z = nn.Linear(self.input_length, self.hidden_length, bias=True)\n",
    "        self.linear_u_z = nn.Linear(self.hidden_length, self.hidden_length, bias=True)\n",
    "        self.linear_us_z = nn.Linear(self.hidden_length_shared, self.hidden_length, bias=True)\n",
    "        self.activation_z = nn.Sigmoid()\n",
    "\n",
    "        # reset gate components\n",
    "        self.linear_w_r = nn.Linear(self.input_length, self.hidden_length, bias=True)\n",
    "        self.linear_u_r = nn.Linear(self.hidden_length, self.hidden_length, bias=True)\n",
    "        self.linear_us_r = nn.Linear(self.hidden_length_shared, self.hidden_length, bias=True)\n",
    "        self.activation_r = nn.Sigmoid()\n",
    "\n",
    "        # new memory components\n",
    "        self.linear_w_hn = nn.Linear(self.input_length, self.hidden_length, bias=True)\n",
    "        self.linear_u_hn = nn.Linear(self.hidden_length, self.hidden_length, bias=True)\n",
    "        self.linear_us_hn = nn.Linear(self.hidden_length_shared, self.hidden_length, bias=True)\n",
    "        self.activation_hn = nn.Tanh()\n",
    "\n",
    "    def update_gate(self, x, h_prev, h_shared_new):\n",
    "        x_new = self.linear_w_z(x)\n",
    "        h_new = self.linear_u_z(h_prev)\n",
    "        hs_new = self.linear_us_z(h_shared_new)\n",
    "        z = self.activation_z(x_new + h_new + hs_new)\n",
    "        return z\n",
    "\n",
    "    def reset_gate(self, x, h_prev, h_shared_new):\n",
    "        x_new = self.linear_w_r(x)\n",
    "        h_new = self.linear_u_r(h_prev)\n",
    "        hs_new = self.linear_us_r(h_shared_new)\n",
    "        r = self.activation_r(x_new + h_new + hs_new)\n",
    "        return r\n",
    "\n",
    "    def new_memory(self, x, h_prev, h_shared_new, r):\n",
    "        x_new = self.linear_w_hn(x)\n",
    "        h_new = r * self.linear_u_hn(h_prev)\n",
    "        hs_new = self.linear_us_hn(h_shared_new)\n",
    "        nm = self.activation_hn(x_new + h_new + hs_new)\n",
    "        return nm\n",
    "\n",
    "    def forward(self, x, h_prev, h_shared_new):\n",
    "        # Equation 1: the update gate\n",
    "        z = self.update_gate(x, h_prev, h_shared_new)\n",
    "\n",
    "        # Equation 2. reset gate vector\n",
    "        r = self.reset_gate(x, h_prev, h_shared_new)\n",
    "\n",
    "        # Equation 3: The new memory component\n",
    "        nm = self.new_memory(x, h_prev, h_shared_new, r)\n",
    "\n",
    "        # Equation 4: the new hidden state\n",
    "        h_new = (1 - z) * nm + z * h_prev\n",
    "\n",
    "        return h_new"
   ]
  },
  {
   "source": [
    "For the shared layer we will use the existing implementation of [*torch.nn.GRUCell*](https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html#torch.nn.GRUCell).\n",
    "\n",
    "\n",
    "### The Multi-task model implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUMultiTask(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Our implementation of the Multi-task GRU model, containing 3 GRU layers: 1 shared layer for both tasks\n",
    "    and task specific layer for each task.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_length=250, hidden_length_rumors=100, hidden_length_stances=100, hidden_length_shared=100,\n",
    "                 loss_func='CrossEntropyLoss', is_dropout=False, drop_prob=0):\n",
    "        super(GRUMultiTask, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.hidden_length_rumors = hidden_length_rumors\n",
    "        self.hidden_length_stances = hidden_length_stances\n",
    "        self.hidden_length_shared = hidden_length_shared\n",
    "        self.is_dropout = is_dropout\n",
    "\n",
    "        if loss_func != 'CrossEntropyLoss' and loss_func != 'BCELoss' and loss_func != 'L1Loss' \\\n",
    "                and loss_func != 'MSELoss':\n",
    "            self.loss_func = 'CrossEntropyLoss'\n",
    "        else:\n",
    "            self.loss_func = loss_func\n",
    "\n",
    "        self.gru_cell_rumors = GRUCellTaskSpecific(self.input_length, self.hidden_length_rumors, \n",
    "                                                   self.hidden_length_shared)\n",
    "        self.gru_cell_stances = GRUCellTaskSpecific(self.input_length, self.hidden_length_stances, \n",
    "                                                    self.hidden_length_shared)\n",
    "        self.gru_cell_shared = nn.GRUCell(self.input_length, self.hidden_length_shared, bias=True)\n",
    "\n",
    "        # for final classification\n",
    "        self.linear_v_rumors = nn.Linear(self.hidden_length_rumors, output_dim_rumors, bias=True)\n",
    "        self.linear_v_stances = nn.Linear(self.hidden_length_stances, output_dim_stances, bias=True)\n",
    "\n",
    "        if self.is_dropout:\n",
    "            self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "        # if we use CrossEntropyLoss we don't need to apply softmax because\n",
    "        # it (CrossEntropyLoss) apply a log_softmax layer after our final layer\n",
    "        if self.loss_func != 'CrossEntropyLoss':\n",
    "            self.activation_y_softmax_rumors = nn.Softmax(dim=0)\n",
    "            self.activation_y_softmax_stances = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, batch, h_prev_shared, m, h_prev_rumors=None, h_prev_stances=None):\n",
    "        outputs = []\n",
    "        for raw in batch:\n",
    "            r = raw.view(1, self.input_length)\n",
    "            h_s = h_prev_shared.view(1, self.hidden_length_shared)\n",
    "            h_prev_shared = self.gru_cell_shared(r, h_s)\n",
    "            h_prev_shared = h_prev_shared.view(self.hidden_length_shared)\n",
    "\n",
    "            if m == task_rumors_no:\n",
    "                h_prev_rumors = self.gru_cell_rumors(raw, h_prev_rumors, h_prev_shared)\n",
    "                if self.is_dropout:\n",
    "                    h_prev_rumors = self.dropout(h_prev_rumors)\n",
    "                v = self.linear_v_rumors(h_prev_rumors)\n",
    "                if self.loss_func != 'CrossEntropyLoss':\n",
    "                    output = self.activation_y_softmax_rumors(v)\n",
    "                else:\n",
    "                    output = v\n",
    "            else:  # m == task_stances_no\n",
    "                h_prev_stances = self.gru_cell_stances(raw, h_prev_stances, h_prev_shared)\n",
    "                if self.is_dropout:\n",
    "                    h_prev_stances = self.dropout(h_prev_stances)\n",
    "                v = self.linear_v_stances(h_prev_stances)\n",
    "                if self.loss_func != 'CrossEntropyLoss':\n",
    "                    output = self.activation_y_softmax_stances(v)\n",
    "                else:\n",
    "                    output = v\n",
    "\n",
    "            outputs.append(output)\n",
    "        if m == task_rumors_no:\n",
    "            return torch.stack(outputs), h_prev_shared, h_prev_rumors\n",
    "        else:  # m == task_stances_no\n",
    "            return torch.stack(outputs), h_prev_shared, h_prev_stances\n",
    "\n",
    "    def init_hidden(self):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.hidden_length_rumors).zero_(),   # for rumors\n",
    "                  weight.new(self.hidden_length_stances).zero_(),  # for stances\n",
    "                  weight.new(self.hidden_length_shared).zero_())   # for shared\n",
    "        return hidden"
   ]
  },
  {
   "source": [
    "## Dataset  \n",
    "Our data dataset is a combination of:\n",
    "-  [*RumourEval 2019 data*](https://figshare.com/articles/RumourEval_2019_data/8845580)\n",
    "-  [*Twitter 15-16*](https://www.dropbox.com/s/7ewzdrbelpmrnxu/rumdetect2017.zip?file_subpath=%2Frumor_detection_acl2017)\n",
    "\n",
    "After preprocessing:  \n",
    "\n",
    "For rumor detection task:  \n",
    "\n",
    "|             |   True rumor   |   False rumor   |   Unverified   |   Total   |\n",
    "|:------------|:--------------:|:---------------:|:--------------:|:---------:|\n",
    "| **Training**| 627 | 531 | 551 | 1709 |\n",
    "| **Validation**| 58 | 68 | 74 | 200 |\n",
    "| **Test**| 61 | 79 | 60 | 200 |\n",
    "\n",
    "For stance detection task:  \n",
    "\n",
    "|             |   Support   |   Deny   |   Query   |   Comment   |   Total   |\n",
    "|:------------|:--------------:|:---------------:|:--------------:|:--------------:|:---------:|\n",
    "| **Training**| 869 | 323 | 325 | 2677 | 4194 |\n",
    "| **Validation**| 92 | 69 | 101 | 699 | 961 |\n",
    "| **Test**| 112 | 81 | 57 | 668 | 918 |\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Train the model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Training loss rumors: 1.091\n",
      "Training accuracy rumors: 37.812%\n",
      "Training loss stances: 1.029\n",
      "Training accuracy stances: 63.020%\n",
      "-----------------------------------------\n",
      "Total runtime:  0:00:13\n",
      "-----------------------------------------\n",
      "\n",
      "Epoch: 2\n",
      "Training loss rumors: 1.023\n",
      "Training accuracy rumors: 49.822%\n",
      "Training loss stances: 0.987\n",
      "Training accuracy stances: 64.090%\n",
      "-----------------------------------------\n",
      "Total runtime:  0:00:28\n",
      "-----------------------------------------\n",
      "\n",
      "Epoch: 3\n",
      "Training loss rumors: 0.893\n",
      "Training accuracy rumors: 59.988%\n",
      "Training loss stances: 0.945\n",
      "Training accuracy stances: 65.279%\n",
      "-----------------------------------------\n",
      "Total runtime:  0:00:41\n",
      "-----------------------------------------\n",
      "\n",
      "Epoch: 4\n",
      "Training loss rumors: 0.800\n",
      "Training accuracy rumors: 65.577%\n",
      "Training loss stances: 0.919\n",
      "Training accuracy stances: 66.350%\n",
      "-----------------------------------------\n",
      "Total runtime:  0:00:53\n",
      "-----------------------------------------\n",
      "\n",
      "Epoch: 5\n",
      "Validation of model: \n",
      "Epoch: 5/5... batch: 1\n",
      " Loss train for rumors: 0.562212... Loss train for stances: 0.819157\n",
      " Val Loss for rumors: 0.874498 Val Loss for stances: 0.904295\n",
      " Val Loss avg: 0.889396\n",
      "Validation loss decreased (inf --> 0.889396).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 2\n",
      " Loss train for rumors: 0.681051... Loss train for stances: 1.155741\n",
      " Val Loss for rumors: 0.864428 Val Loss for stances: 0.899441\n",
      " Val Loss avg: 0.881935\n",
      "Validation loss decreased (0.889396 --> 0.881935).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 3\n",
      " Loss train for rumors: 0.697989... Loss train for stances: 0.869920\n",
      " Val Loss for rumors: 0.834372 Val Loss for stances: 0.892581\n",
      " Val Loss avg: 0.863477\n",
      "Validation loss decreased (0.881935 --> 0.863477).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 4\n",
      " Loss train for rumors: 0.889587... Loss train for stances: 0.627922\n",
      " Val Loss for rumors: 0.809919 Val Loss for stances: 0.881564\n",
      " Val Loss avg: 0.845741\n",
      "Validation loss decreased (0.863477 --> 0.845741).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 5\n",
      " Loss train for rumors: 0.777459... Loss train for stances: 1.090703\n",
      " Val Loss for rumors: 0.814062 Val Loss for stances: 0.874186\n",
      " Val Loss avg: 0.844124\n",
      "Validation loss decreased (0.845741 --> 0.844124).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 6\n",
      " Loss train for rumors: 0.589853... Loss train for stances: 0.612769\n",
      " Val Loss for rumors: 0.820056 Val Loss for stances: 0.875277\n",
      " Val Loss avg: 0.847667\n",
      "\n",
      "Epoch: 5/5... batch: 7\n",
      " Loss train for rumors: 0.759008... Loss train for stances: 0.838227\n",
      " Val Loss for rumors: 0.823616 Val Loss for stances: 0.880405\n",
      " Val Loss avg: 0.852010\n",
      "\n",
      "Epoch: 5/5... batch: 8\n",
      " Loss train for rumors: 0.788118... Loss train for stances: 0.946883\n",
      " Val Loss for rumors: 0.812747 Val Loss for stances: 0.886832\n",
      " Val Loss avg: 0.849789\n",
      "\n",
      "Epoch: 5/5... batch: 9\n",
      " Loss train for rumors: 0.511962... Loss train for stances: 0.992561\n",
      " Val Loss for rumors: 0.803194 Val Loss for stances: 0.891234\n",
      " Val Loss avg: 0.847214\n",
      "\n",
      "Epoch: 5/5... batch: 10\n",
      " Loss train for rumors: 0.600275... Loss train for stances: 1.296034\n",
      " Val Loss for rumors: 0.800826 Val Loss for stances: 0.893113\n",
      " Val Loss avg: 0.846969\n",
      "\n",
      "Epoch: 5/5... batch: 11\n",
      " Loss train for rumors: 0.613017... Loss train for stances: 0.960016\n",
      " Val Loss for rumors: 0.808062 Val Loss for stances: 0.898080\n",
      " Val Loss avg: 0.853071\n",
      "\n",
      "Epoch: 5/5... batch: 12\n",
      " Loss train for rumors: 0.675459... Loss train for stances: 0.850087\n",
      " Val Loss for rumors: 0.841176 Val Loss for stances: 0.906714\n",
      " Val Loss avg: 0.873945\n",
      "\n",
      "Epoch: 5/5... batch: 13\n",
      " Loss train for rumors: 0.893469... Loss train for stances: 0.938700\n",
      " Val Loss for rumors: 0.867666 Val Loss for stances: 0.908266\n",
      " Val Loss avg: 0.887966\n",
      "\n",
      "Epoch: 5/5... batch: 14\n",
      " Loss train for rumors: 0.712695... Loss train for stances: 0.897492\n",
      " Val Loss for rumors: 0.882189 Val Loss for stances: 0.904878\n",
      " Val Loss avg: 0.893534\n",
      "\n",
      "Epoch: 5/5... batch: 15\n",
      " Loss train for rumors: 0.837328... Loss train for stances: 0.985213\n",
      " Val Loss for rumors: 0.847174 Val Loss for stances: 0.899492\n",
      " Val Loss avg: 0.873333\n",
      "\n",
      "Epoch: 5/5... batch: 16\n",
      " Loss train for rumors: 0.752465... Loss train for stances: 0.893936\n",
      " Val Loss for rumors: 0.811141 Val Loss for stances: 0.895718\n",
      " Val Loss avg: 0.853430\n",
      "\n",
      "Epoch: 5/5... batch: 17\n",
      " Loss train for rumors: 0.637792... Loss train for stances: 1.055228\n",
      " Val Loss for rumors: 0.793523 Val Loss for stances: 0.895690\n",
      " Val Loss avg: 0.844607\n",
      "\n",
      "Epoch: 5/5... batch: 18\n",
      " Loss train for rumors: 0.548346... Loss train for stances: 1.214414\n",
      " Val Loss for rumors: 0.790831 Val Loss for stances: 0.901855\n",
      " Val Loss avg: 0.846343\n",
      "\n",
      "Epoch: 5/5... batch: 19\n",
      " Loss train for rumors: 0.691172... Loss train for stances: 0.931861\n",
      " Val Loss for rumors: 0.790348 Val Loss for stances: 0.908934\n",
      " Val Loss avg: 0.849641\n",
      "\n",
      "Epoch: 5/5... batch: 20\n",
      " Loss train for rumors: 0.849680... Loss train for stances: 0.855511\n",
      " Val Loss for rumors: 0.796945 Val Loss for stances: 0.908124\n",
      " Val Loss avg: 0.852534\n",
      "\n",
      "Epoch: 5/5... batch: 21\n",
      " Loss train for rumors: 0.879336... Loss train for stances: 1.240261\n",
      " Val Loss for rumors: 0.799462 Val Loss for stances: 0.904257\n",
      " Val Loss avg: 0.851859\n",
      "\n",
      "Epoch: 5/5... batch: 22\n",
      " Loss train for rumors: 0.576067... Loss train for stances: 0.948620\n",
      " Val Loss for rumors: 0.795104 Val Loss for stances: 0.900206\n",
      " Val Loss avg: 0.847655\n",
      "\n",
      "Epoch: 5/5... batch: 23\n",
      " Loss train for rumors: 0.655663... Loss train for stances: 0.917344\n",
      " Val Loss for rumors: 0.792444 Val Loss for stances: 0.893787\n",
      " Val Loss avg: 0.843116\n",
      "Validation loss decreased (0.844124 --> 0.843116).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 24\n",
      " Loss train for rumors: 0.587105... Loss train for stances: 0.893639\n",
      " Val Loss for rumors: 0.789152 Val Loss for stances: 0.885037\n",
      " Val Loss avg: 0.837095\n",
      "Validation loss decreased (0.843116 --> 0.837095).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 25\n",
      " Loss train for rumors: 0.875418... Loss train for stances: 0.822910\n",
      " Val Loss for rumors: 0.789234 Val Loss for stances: 0.875369\n",
      " Val Loss avg: 0.832302\n",
      "Validation loss decreased (0.837095 --> 0.832302).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 26\n",
      " Loss train for rumors: 0.837615... Loss train for stances: 1.119966\n",
      " Val Loss for rumors: 0.794560 Val Loss for stances: 0.870867\n",
      " Val Loss avg: 0.832714\n",
      "\n",
      "Epoch: 5/5... batch: 27\n",
      " Loss train for rumors: 0.705114... Loss train for stances: 0.730643\n",
      " Val Loss for rumors: 0.814514 Val Loss for stances: 0.870805\n",
      " Val Loss avg: 0.842660\n",
      "\n",
      "Epoch: 5/5... batch: 28\n",
      " Loss train for rumors: 0.685767... Loss train for stances: 0.637926\n",
      " Val Loss for rumors: 0.825239 Val Loss for stances: 0.873059\n",
      " Val Loss avg: 0.849149\n",
      "\n",
      "Epoch: 5/5... batch: 29\n",
      " Loss train for rumors: 0.526595... Loss train for stances: 0.718863\n",
      " Val Loss for rumors: 0.823572 Val Loss for stances: 0.877900\n",
      " Val Loss avg: 0.850736\n",
      "\n",
      "Epoch: 5/5... batch: 30\n",
      " Loss train for rumors: 0.645347... Loss train for stances: 1.070608\n",
      " Val Loss for rumors: 0.830069 Val Loss for stances: 0.884906\n",
      " Val Loss avg: 0.857487\n",
      "\n",
      "Epoch: 5/5... batch: 31\n",
      " Loss train for rumors: 0.692027... Loss train for stances: 1.133357\n",
      " Val Loss for rumors: 0.841153 Val Loss for stances: 0.890275\n",
      " Val Loss avg: 0.865714\n",
      "\n",
      "Epoch: 5/5... batch: 32\n",
      " Loss train for rumors: 0.661179... Loss train for stances: 0.879352\n",
      " Val Loss for rumors: 0.812459 Val Loss for stances: 0.895805\n",
      " Val Loss avg: 0.854132\n",
      "\n",
      "Epoch: 5/5... batch: 33\n",
      " Loss train for rumors: 0.687884... Loss train for stances: 0.973042\n",
      " Val Loss for rumors: 0.789360 Val Loss for stances: 0.906465\n",
      " Val Loss avg: 0.847913\n",
      "\n",
      "Epoch: 5/5... batch: 34\n",
      " Loss train for rumors: 0.694178... Loss train for stances: 0.728432\n",
      " Val Loss for rumors: 0.783946 Val Loss for stances: 0.914914\n",
      " Val Loss avg: 0.849430\n",
      "\n",
      "Epoch: 5/5... batch: 35\n",
      " Loss train for rumors: 0.672055... Loss train for stances: 0.933804\n",
      " Val Loss for rumors: 0.790149 Val Loss for stances: 0.919516\n",
      " Val Loss avg: 0.854832\n",
      "\n",
      "Epoch: 5/5... batch: 36\n",
      " Loss train for rumors: 0.555764... Loss train for stances: 0.939040\n",
      " Val Loss for rumors: 0.804591 Val Loss for stances: 0.917445\n",
      " Val Loss avg: 0.861018\n",
      "\n",
      "Epoch: 5/5... batch: 37\n",
      " Loss train for rumors: 0.558260... Loss train for stances: 0.927651\n",
      " Val Loss for rumors: 0.837896 Val Loss for stances: 0.908933\n",
      " Val Loss avg: 0.873414\n",
      "\n",
      "Epoch: 5/5... batch: 38\n",
      " Loss train for rumors: 0.623889... Loss train for stances: 0.990295\n",
      " Val Loss for rumors: 0.839452 Val Loss for stances: 0.900749\n",
      " Val Loss avg: 0.870100\n",
      "\n",
      "Epoch: 5/5... batch: 39\n",
      " Loss train for rumors: 0.731166... Loss train for stances: 1.254274\n",
      " Val Loss for rumors: 0.790491 Val Loss for stances: 0.894019\n",
      " Val Loss avg: 0.842255\n",
      "\n",
      "Epoch: 5/5... batch: 40\n",
      " Loss train for rumors: 0.711914... Loss train for stances: 0.856572\n",
      " Val Loss for rumors: 0.769258 Val Loss for stances: 0.887109\n",
      " Val Loss avg: 0.828184\n",
      "Validation loss decreased (0.832302 --> 0.828184).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 41\n",
      " Loss train for rumors: 0.774943... Loss train for stances: 1.002075\n",
      " Val Loss for rumors: 0.809028 Val Loss for stances: 0.880784\n",
      " Val Loss avg: 0.844906\n",
      "\n",
      "Epoch: 5/5... batch: 42\n",
      " Loss train for rumors: 0.729644... Loss train for stances: 1.043324\n",
      " Val Loss for rumors: 0.816225 Val Loss for stances: 0.876695\n",
      " Val Loss avg: 0.846460\n",
      "\n",
      "Epoch: 5/5... batch: 43\n",
      " Loss train for rumors: 0.635426... Loss train for stances: 0.882916\n",
      " Val Loss for rumors: 0.820369 Val Loss for stances: 0.873258\n",
      " Val Loss avg: 0.846814\n",
      "\n",
      "Epoch: 5/5... batch: 44\n",
      " Loss train for rumors: 0.798110... Loss train for stances: 0.803671\n",
      " Val Loss for rumors: 0.815475 Val Loss for stances: 0.867069\n",
      " Val Loss avg: 0.841272\n",
      "\n",
      "Epoch: 5/5... batch: 45\n",
      " Loss train for rumors: 0.712003... Loss train for stances: 0.894750\n",
      " Val Loss for rumors: 0.806195 Val Loss for stances: 0.859359\n",
      " Val Loss avg: 0.832777\n",
      "\n",
      "Epoch: 5/5... batch: 46\n",
      " Loss train for rumors: 0.817377... Loss train for stances: 1.020675\n",
      " Val Loss for rumors: 0.785521 Val Loss for stances: 0.855048\n",
      " Val Loss avg: 0.820284\n",
      "Validation loss decreased (0.828184 --> 0.820284).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 47\n",
      " Loss train for rumors: 0.764546... Loss train for stances: 0.728883\n",
      " Val Loss for rumors: 0.775270 Val Loss for stances: 0.853990\n",
      " Val Loss avg: 0.814630\n",
      "Validation loss decreased (0.820284 --> 0.814630).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 48\n",
      " Loss train for rumors: 0.463344... Loss train for stances: 0.819157\n",
      " Val Loss for rumors: 0.789878 Val Loss for stances: 0.854021\n",
      " Val Loss avg: 0.821949\n",
      "\n",
      "Epoch: 5/5... batch: 49\n",
      " Loss train for rumors: 0.737612... Loss train for stances: 0.762822\n",
      " Val Loss for rumors: 0.790485 Val Loss for stances: 0.856234\n",
      " Val Loss avg: 0.823360\n",
      "\n",
      "Epoch: 5/5... batch: 50\n",
      " Loss train for rumors: 0.762960... Loss train for stances: 0.907421\n",
      " Val Loss for rumors: 0.761565 Val Loss for stances: 0.861759\n",
      " Val Loss avg: 0.811662\n",
      "Validation loss decreased (0.814630 --> 0.811662).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 51\n",
      " Loss train for rumors: 0.812022... Loss train for stances: 0.715292\n",
      " Val Loss for rumors: 0.751376 Val Loss for stances: 0.869841\n",
      " Val Loss avg: 0.810608\n",
      "Validation loss decreased (0.811662 --> 0.810608).  Saving model ...\n",
      "\n",
      "Epoch: 5/5... batch: 52\n",
      " Loss train for rumors: 0.682870... Loss train for stances: 0.756489\n",
      " Val Loss for rumors: 0.744901 Val Loss for stances: 0.879747\n",
      " Val Loss avg: 0.812324\n",
      "\n",
      "Epoch: 5/5... batch: 53\n",
      " Loss train for rumors: 0.697424... Loss train for stances: 0.913421\n",
      " Val Loss for rumors: 0.737908 Val Loss for stances: 0.885577\n",
      " Val Loss avg: 0.811742\n",
      "\n",
      "Epoch: 5/5... batch: 54\n",
      " Loss train for rumors: 0.705343... Loss train for stances: 0.811558\n",
      " Val Loss for rumors: 0.741082 Val Loss for stances: 0.886398\n",
      " Val Loss avg: 0.813740\n",
      "\n",
      "Epoch: 5/5... batch: 55\n",
      " Loss train for rumors: 0.645561... Loss train for stances: 1.029290\n",
      " Val Loss for rumors: 0.745323 Val Loss for stances: 0.883178\n",
      " Val Loss avg: 0.814250\n",
      "\n",
      "Epoch: 5/5... batch: 56\n",
      " Loss train for rumors: 0.564031... Loss train for stances: 0.829808\n",
      " Val Loss for rumors: 0.751058 Val Loss for stances: 0.877273\n",
      " Val Loss avg: 0.814165\n",
      "\n",
      "Epoch: 5/5... batch: 57\n",
      " Loss train for rumors: 0.843137... Loss train for stances: 0.722009\n",
      " Val Loss for rumors: 0.767290 Val Loss for stances: 0.873822\n",
      " Val Loss avg: 0.820556\n",
      "\n",
      "Epoch: 5/5... batch: 58\n",
      " Loss train for rumors: 0.620758... Loss train for stances: 0.713100\n",
      " Val Loss for rumors: 0.790183 Val Loss for stances: 0.874116\n",
      " Val Loss avg: 0.832150\n",
      "\n",
      "Training loss rumors: 0.697\n",
      "Training accuracy rumors: 70.690%\n",
      "Training loss stances: 0.912\n",
      "Training accuracy stances: 66.231%\n",
      "-----------------------------------------\n",
      "Validation accuracy rumors: 65.026%\n",
      "Validation accuracy stances: 71.104%\n",
      "-----------------------------------------\n",
      "Last save for model: epoch 5\n",
      "-----------------------------------------\n",
      "Total runtime:  0:03:14\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Preprocessed data paths\n",
    "preprocessed_data_paths = {\n",
    "    'training_rumors_tweets path':      os.path.join('data', 'preprocessed data', 'training', 'rumors_tweets.npy'),\n",
    "    'training_rumors_labels path':      os.path.join('data', 'preprocessed data', 'training', 'rumors_labels.npy'),\n",
    "    'training_stances_tweets path':     os.path.join('data', 'preprocessed data', 'training', 'stances_tweets.npy'),\n",
    "    'training_stances_labels path':     os.path.join('data', 'preprocessed data', 'training', 'stances_labels.npy'),\n",
    "\n",
    "    'validation_rumors_tweets path':    os.path.join('data', 'preprocessed data', 'validation', 'rumors_tweets.npy'),\n",
    "    'validation_rumors_labels path':    os.path.join('data', 'preprocessed data', 'validation', 'rumors_labels.npy'),\n",
    "    'validation_stances_tweets path':   os.path.join('data', 'preprocessed data', 'validation', 'stances_tweets.npy'),\n",
    "    'validation_stances_labels path':   os.path.join('data', 'preprocessed data', 'validation', 'stances_labels.npy'),\n",
    "}\n",
    "\n",
    "batch_size_training_rumors = 28\n",
    "batch_size_training_stances = 28\n",
    "\n",
    "batch_size_validation_rumors = 20  # 200\n",
    "batch_size_validation_stances = 96  # 961\n",
    "\n",
    "loss_function = 'CrossEntropyLoss'      # supported options: CrossEntropyLoss | BCELoss | L1Loss | MSELoss\n",
    "learning_rate = 0.0005                  # learning rate\n",
    "epochs = 5\n",
    "\n",
    "is_dropout = False  # can be True or False\n",
    "drop_prob = 0.0\n",
    "\n",
    "\n",
    "def training():\n",
    "    # create 'TensorDataset's for rumors\n",
    "    train_data_rumors = TensorDataset(torch.from_numpy(np.load(preprocessed_data_paths['training_rumors_tweets path'])),\n",
    "                                      torch.from_numpy(np.load(preprocessed_data_paths['training_rumors_labels path'])))\n",
    "    val_data_rumors = TensorDataset(torch.from_numpy(np.load(preprocessed_data_paths['validation_rumors_tweets path'])),\n",
    "                                    torch.from_numpy(np.load(preprocessed_data_paths['validation_rumors_labels path'])))\n",
    "\n",
    "    train_loader_rumors = DataLoader(train_data_rumors, shuffle=True, batch_size=batch_size_training_rumors, drop_last=True)\n",
    "    val_loader_rumors = DataLoader(val_data_rumors, shuffle=False, batch_size=batch_size_validation_rumors, drop_last=True)\n",
    "\n",
    "    # create 'TensorDataset's  for stances\n",
    "    train_data_stances = TensorDataset(torch.from_numpy(np.load(preprocessed_data_paths['training_stances_tweets path'])),\n",
    "                                       torch.from_numpy(np.load(preprocessed_data_paths['training_stances_labels path'])))\n",
    "\n",
    "    val_data_stances = TensorDataset(torch.from_numpy(np.load(preprocessed_data_paths['validation_stances_tweets path'])),\n",
    "                                     torch.from_numpy(np.load(preprocessed_data_paths['validation_stances_labels path'])))\n",
    "\n",
    "    # create 'DataLoader's  for stances\n",
    "    train_loader_stances = DataLoader(train_data_stances, shuffle=True, batch_size=batch_size_training_stances, drop_last=True)\n",
    "    val_loader_stances = DataLoader(val_data_stances, shuffle=False, batch_size=batch_size_validation_stances, drop_last=True)\n",
    "\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # if we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    # create the model\n",
    "    model = GRUMultiTask(input_length=input_length,\n",
    "                         hidden_length_rumors=hidden_length_rumors,\n",
    "                         hidden_length_stances=hidden_length_stances,\n",
    "                         hidden_length_shared=hidden_length_shared,\n",
    "                         loss_func=loss_function,\n",
    "                         is_dropout=is_dropout,\n",
    "                         drop_prob=drop_prob\n",
    "                         )\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss\n",
    "    if loss_function == 'BCELoss':\n",
    "        criterion = nn.BCELoss()\n",
    "    elif loss_function == 'L1Loss':\n",
    "        criterion = nn.L1Loss()\n",
    "    elif loss_function == 'MSELoss':\n",
    "        criterion = nn.MSELoss()\n",
    "    else:  # the default\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # train the model\n",
    "    model.train()  # set the model to train mode\n",
    "\n",
    "    validation_min_loss = {\n",
    "        'min loss': np.Inf\n",
    "    }\n",
    "\n",
    "    last_save = {\n",
    "        'last save': 0,\n",
    "    }\n",
    "\n",
    "    # check time before training\n",
    "    start_time = gmtime()\n",
    "    start_time = strftime(\"%H:%M:%S\", start_time)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        h = model.init_hidden()\n",
    "        print('\\nEpoch: ' + str(i + 1))\n",
    "\n",
    "        counter_batches = 0\n",
    "        cnt_correct_training_rumors = 0\n",
    "        cnt_correct_training_stances = 0\n",
    "        cnt_correct_validation_rumors = 0\n",
    "        cnt_correct_validation_stances = 0\n",
    "        sum_loss_training_rumors = 0\n",
    "        sum_loss_training_stances = 0\n",
    "\n",
    "        # iterate through all the batch\n",
    "        for (inputs_rumors, labels_rumors), (inputs_stances, labels_stances) \\\n",
    "                in zip(train_loader_rumors, train_loader_stances):\n",
    "            counter_batches += 1\n",
    "\n",
    "            # make training\n",
    "            loss_rumors, cnt_correct = training_batch_iter(model, 'rumor', criterion, optimizer, device,\n",
    "                                                           inputs_rumors, labels_rumors, h)\n",
    "            cnt_correct_training_rumors += cnt_correct\n",
    "            sum_loss_training_rumors += loss_rumors.item()\n",
    "\n",
    "            loss_stances, cnt_correct = training_batch_iter(model, 'stance', criterion, optimizer, device,\n",
    "                                                            inputs_stances, labels_stances, h)\n",
    "            cnt_correct_training_stances += cnt_correct\n",
    "            sum_loss_training_stances += loss_stances.item()\n",
    "\n",
    "            # make validation and save the model if it is the best until now\n",
    "            if i > 3:  # start validation only from epoch 5\n",
    "                if 1 == counter_batches:\n",
    "                    print('Validation of model: ')\n",
    "                cnt_correct_r, cnt_correct_s = validation_or_testing(model, val_loader_rumors, val_loader_stances,\n",
    "                                                                     criterion, device, i+1, validation_min_loss,\n",
    "                                                                     loss_rumors, loss_stances, counter_batches, last_save)\n",
    "                cnt_correct_validation_rumors += cnt_correct_r\n",
    "                cnt_correct_validation_stances += cnt_correct_s\n",
    "\n",
    "        # print accuracy and loss of the training\n",
    "        training_loss_rumors = sum_loss_training_rumors / counter_batches\n",
    "        print(\"Training loss rumors: {:.3f}\".format(training_loss_rumors))\n",
    "        training_acc_rumors = cnt_correct_training_rumors / (batch_size_training_rumors * counter_batches)\n",
    "        print(\"Training accuracy rumors: {:.3f}%\".format(training_acc_rumors * 100))\n",
    "\n",
    "        training_loss_stances = sum_loss_training_stances / counter_batches\n",
    "        print(\"Training loss stances: {:.3f}\".format(training_loss_stances))\n",
    "        training_acc_stances = cnt_correct_training_stances / (batch_size_training_stances * counter_batches)\n",
    "        print(\"Training accuracy stances: {:.3f}%\".format(training_acc_stances * 100))\n",
    "\n",
    "        # print accuracy of the validation\n",
    "        if i > 3:\n",
    "            print('-----------------------------------------')\n",
    "\n",
    "            validation_acc_rumors = cnt_correct_validation_rumors / (len(val_loader_rumors.dataset) * counter_batches)\n",
    "            print(\"Validation accuracy rumors: {:.3f}%\".format(validation_acc_rumors * 100))\n",
    "\n",
    "            validation_acc_stances = cnt_correct_validation_stances / (len(val_loader_stances.dataset) * counter_batches)\n",
    "            print(\"Validation accuracy stances: {:.3f}%\".format(validation_acc_stances * 100))\n",
    "\n",
    "            print('-----------------------------------------')\n",
    "\n",
    "            print('Last save for model: epoch ' + str(last_save['last save']))\n",
    "\n",
    "        # check time so far\n",
    "        finish_time = gmtime()\n",
    "        finish_time = strftime(\"%H:%M:%S\", finish_time)\n",
    "        formats = \"%H:%M:%S\"\n",
    "        time_so_far = datetime.strptime(finish_time, formats) - datetime.strptime(start_time, formats)\n",
    "        print('-----------------------------------------')\n",
    "        print(\"Total runtime: \", time_so_far)\n",
    "        print('-----------------------------------------')\n",
    "\n",
    "\n",
    "def training_batch_iter(model, task_name, criterion, optimizer, device, inputs_batch, labels_batch, h):\n",
    "    \"\"\"\n",
    "    Makes the forward step of specific task and returns the loss and number of correct predictions\n",
    "    :param model:           the multi-task model\n",
    "    :param task_name:       'rumor' or 'stances'\n",
    "    :param criterion:       the loss function\n",
    "    :param optimizer:       the optimizer\n",
    "    :param device:          'cpu' or 'gpu'\n",
    "    :param inputs_batch:    the inputs batch\n",
    "    :param labels_batch:    the target labels batch\n",
    "    :param h:               the initial 'h_t's\n",
    "    :return:                - loss of the batch\n",
    "                            - number of correct predictions\n",
    "    \"\"\"\n",
    "    # set initial 'h' vectors of model's GRUs\n",
    "    h_prev_task_rumors, h_prev_task_stances, h_prev_shared = h\n",
    "\n",
    "    inputs_batch, labels_batch = inputs_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "    # Clear gradients parameters\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass to get outputs of the model\n",
    "    if 'rumor' == task_name:\n",
    "        outputs, h_prev_shared, h_prev_task_rumors = model(inputs_batch, h_prev_shared, task_rumors_no,\n",
    "                                                           h_prev_rumors=h_prev_task_rumors)\n",
    "    else:  # 'stance' == task_name\n",
    "        outputs, h_prev_shared, h_prev_task_stances = model(inputs_batch, h_prev_shared, task_stances_no,\n",
    "                                                            h_prev_stances=h_prev_task_stances)\n",
    "\n",
    "    # Calculate Loss\n",
    "    if loss_function == 'BCELoss' or loss_function == 'MSELoss':\n",
    "        loss = criterion(outputs, labels_batch.float())\n",
    "    elif loss_function == 'L1Loss':\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "    else:  # the default\n",
    "        loss = criterion(outputs, (torch.max(labels_batch, 1)[1]).to(device))\n",
    "\n",
    "    # Getting gradients parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # count the number of correct outputs\n",
    "    num_correct = count_correct(outputs, labels_batch, task_name, device)\n",
    "\n",
    "    return loss, num_correct\n",
    "\n",
    "\n",
    "def validation_or_testing(model, data_loader_rumors, data_loader_stances, criterion, device, epoch_no=None,\n",
    "                          min_loss_dict=None, loss_train_r=None, loss_train_s=None, batch_no=None, last_save_dict=None,\n",
    "                          operation='validation'):\n",
    "    \"\"\"\n",
    "    Makes validation on specific task. Saves the dict of the model if it gave the best results so far.\n",
    "    Returns the number of correct predictions\n",
    "    :param model:                       the multi-task model\n",
    "    :param data_loader_rumors:          DataLoader of rumor detection task\n",
    "    :param data_loader_stances:         DataLoader of stance detection task\n",
    "    :param criterion:                   the loss function\n",
    "    :param device:                      'cpu' or 'gpu'\n",
    "    :param epoch_no:                    epoch no\n",
    "    :param min_loss_dict:               dictionary that contains the min losses of each task\n",
    "    :param loss_train_r :               the loss of the training at this point of time for rumor detection task\n",
    "    :param loss_train_s :               the loss of the training at this point of time for stance detection task\n",
    "    :param batch_no:                    batch no\n",
    "    :param last_save_dict               dictionary containing the last epoch where a save happened for each task\n",
    "    :param operation                    validation' or 'testing'\n",
    "    :return:                            number of correct predictions\n",
    "    \"\"\"\n",
    "    all_losses_r = []  # for rumor detection task\n",
    "    all_losses_s = []  # for stance detection task\n",
    "\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "\n",
    "    sum_correct_r = 0  # for rumor detection task\n",
    "    sum_correct_s = 0  # for stance detection task\n",
    "\n",
    "    total_out_r = []  # for rumor detection task\n",
    "    total_lab_r = []  # for rumor detection task\n",
    "    total_out_s = []  # for stance detection task\n",
    "    total_lab_s = []  # for stance detection task\n",
    "\n",
    "    # get initial 'h' vectors of model's GRUs\n",
    "    h_prev_task_rumors_val, h_prev_task_stances_val, h_prev_shared_val = model.init_hidden()\n",
    "\n",
    "    # iterate through the batch\n",
    "    for (inputs_rumors, labels_rumors), (inputs_stances, labels_stances) \\\n",
    "            in zip(data_loader_rumors, data_loader_stances):\n",
    "        inputs_rumors, labels_rumors = inputs_rumors.to(device), labels_rumors.to(device)\n",
    "        inputs_stances, labels_stances = inputs_stances.to(device), labels_stances.to(device)\n",
    "\n",
    "        # Forward pass for rumor task, to get outputs of the model\n",
    "        out_r, h_prev_shared_val, h_prev_task_rumors_val = model(inputs_rumors, h_prev_shared_val, task_rumors_no,\n",
    "                                                                 h_prev_rumors=h_prev_task_rumors_val)\n",
    "        # Forward pass for stance task, to get outputs of the model\n",
    "        out_s, h_prev_shared_val, h_prev_task_stances_val = model(inputs_stances, h_prev_shared_val, task_stances_no,\n",
    "                                                                  h_prev_stances=h_prev_task_stances_val)\n",
    "\n",
    "        # we need this for calculation of F1 scores. we do it only for testing\n",
    "        if 'testing' == operation:\n",
    "            total_out_r += (torch.max(out_r, 1)[1]).to('cpu').tolist()\n",
    "            total_lab_r += (torch.max(labels_rumors, 1)[1]).to('cpu').tolist()\n",
    "            total_out_s += (torch.max(out_s, 1)[1]).to('cpu').tolist()\n",
    "            total_lab_s += (torch.max(labels_stances, 1)[1]).to('cpu').tolist()\n",
    "\n",
    "        # count the number of correct outputs\n",
    "        sum_correct_r += count_correct(out_r, labels_rumors, 'rumor', device)\n",
    "        sum_correct_s += count_correct(out_s, labels_stances, 'stance', device)\n",
    "\n",
    "        # Calculate Loss\n",
    "        if loss_function == 'BCELoss' or loss_function == 'MSELoss':\n",
    "            loss_r = criterion(out_r, labels_rumors.float())\n",
    "            loss_s = criterion(out_s, labels_stances.float())\n",
    "        elif loss_function == 'L1Loss':\n",
    "            loss_r = criterion(out_r, labels_rumors)\n",
    "            loss_s = criterion(out_s, labels_stances)\n",
    "        else:  # the default\n",
    "            loss_r = criterion(out_r, (torch.max(labels_rumors, 1)[1]).to(device))\n",
    "            loss_s = criterion(out_s, (torch.max(labels_stances, 1)[1]).to(device))\n",
    "        all_losses_r.append(loss_r.item())\n",
    "        all_losses_s.append(loss_s.item())\n",
    "\n",
    "    # calculation of F1 scores\n",
    "    if 'testing' == operation:\n",
    "        # print F1 micro and macro scores for rumor detection\n",
    "        score_f1_micro = f1_score(total_lab_r, total_out_r, average='micro')\n",
    "        score_f1_macro = f1_score(total_lab_r, total_out_r, average='macro')\n",
    "        print(\"For rumor detection:\")\n",
    "        print(\"F1 micro score: {:.3f}\".format(score_f1_micro))\n",
    "        print(\"F1 macro score: {:.3f}\\n\".format(score_f1_macro))\n",
    "\n",
    "        # print F1 micro and macro scores for stance detection\n",
    "        score_f1_micro = f1_score(total_lab_s, total_out_s, average='micro')\n",
    "        score_f1_macro = f1_score(total_lab_s, total_out_s, average='macro')\n",
    "        print(\"For stance detection:\")\n",
    "        print(\"F1 micro score: {:.3f}\".format(score_f1_micro))\n",
    "        print(\"F1 macro score: {:.3f}\".format(score_f1_macro))\n",
    "\n",
    "    if 'validation' == operation:\n",
    "        print_and_save(model, epoch_no, batch_no, loss_train_r, loss_train_s, all_losses_r, all_losses_s, min_loss_dict,\n",
    "                       last_save_dict)\n",
    "\n",
    "    return sum_correct_r, sum_correct_s\n",
    "\n",
    "\n",
    "def print_and_save(model, epoch_no, batch_no, loss_train_r, loss_train_s, all_losses_r, all_losses_s, min_loss_dict,\n",
    "                   last_save_dict):\n",
    "    \"\"\"\n",
    "    Prints the details of the validation and saves the dict of the model if it gave the best results so far.\n",
    "    :param model:                       the multi-task model\n",
    "    :param epoch_no:                    epoch no\n",
    "    :param batch_no:                    batch no\n",
    "    :param loss_train_r:                the loss of the training for rumor detection task\n",
    "    :param loss_train_s:                the loss of the training for stance detection task\n",
    "    :param all_losses_r:                list with all the losses of the validation for rumor detection task\n",
    "    :param all_losses_s:                list with all the losses of the validation for stance detection task\n",
    "    :param min_loss_dict:               dictionary that contains the min losses of each task\n",
    "    :param last_save_dict               dictionary containing the the last epoch where a save happened for each task\n",
    "    :return:                            void\n",
    "    \"\"\"\n",
    "    model.train()  # set the model to train mode\n",
    "\n",
    "    val_loss_avg = (np.mean(all_losses_r) + np.mean(all_losses_s)) / 2\n",
    "    print(\"Epoch: {}/{}...\".format(epoch_no, epochs),\n",
    "          \"batch: {}\\n\".format(batch_no),\n",
    "          \"Loss train for rumors: {:.6f}...\".format(loss_train_r.item()),\n",
    "          \"Loss train for stances: {:.6f}\\n\".format(loss_train_s.item()),\n",
    "          \"Val Loss for rumors: {:.6f}\".format(np.mean(all_losses_r)),\n",
    "          \"Val Loss for stances: {:.6f}\\n\".format(np.mean(all_losses_s)),\n",
    "          \"Val Loss avg: {:.6f}\".format(val_loss_avg))\n",
    "    if val_loss_avg <= min_loss_dict['min loss']:\n",
    "        torch.save(model.state_dict(), 'model/model_state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...\\n'.format(min_loss_dict['min loss'],\n",
    "                                                                                          val_loss_avg))\n",
    "        min_loss_dict['min loss'] = val_loss_avg\n",
    "        last_save_dict['last save'] = epoch_no\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "\n",
    "def count_correct(outputs, labels_batch, task_name, device):\n",
    "    \"\"\"\n",
    "    Counts the number of correct outputs (predictions)\n",
    "    :param outputs:         the predictions of the model\n",
    "    :param labels_batch:    the labels (targets)\n",
    "    :param task_name:       'rumor' or 'stances'\n",
    "    :param device:          'cpu' or 'gpu'\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    for out, label in zip(outputs, labels_batch):\n",
    "        max_idx = torch.argmax(out, dim=0)  # dim=0 means: look in the first row\n",
    "        if 'rumor' == task_name:\n",
    "            one_hot = torch.nn.functional.one_hot(torch.tensor([max_idx]), output_dim_rumors)\n",
    "        else:  # 'stance' == task_name\n",
    "            one_hot = torch.nn.functional.one_hot(torch.tensor([max_idx]), output_dim_stances)\n",
    "        one_hot = torch.squeeze(one_hot, 0)\n",
    "        one_hot = one_hot.to(device)\n",
    "        if torch.equal(label, one_hot):\n",
    "            num_correct += 1\n",
    "\n",
    "    return num_correct\n",
    "\n",
    "training()\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Test the model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For rumor detection:\nF1 micro score: 0.645\nF1 macro score: 0.627\n\nFor stance detection:\nF1 micro score: 0.726\nF1 macro score: 0.215\n-----------------------------------------\n\nTest accuracy rumors: 64.500%\nTest accuracy stances: 72.004%\n"
     ]
    }
   ],
   "source": [
    "# Preprocessed data paths\n",
    "preprocessed_data_paths = {\n",
    "    'test_rumors_tweets path':      os.path.join('data', 'preprocessed data', 'test', 'rumors_tweets.npy'),\n",
    "    'test_rumors_labels path':      os.path.join('data', 'preprocessed data', 'test', 'rumors_labels.npy'),\n",
    "    'test_stances_tweets path':     os.path.join('data', 'preprocessed data', 'test', 'stances_tweets.npy'),\n",
    "    'test_stances_labels path':     os.path.join('data', 'preprocessed data', 'test', 'stances_labels.npy'),\n",
    "}\n",
    "\n",
    "batch_size_test_rumors = 20  # 200\n",
    "batch_size_test_stances = 91  # 918\n",
    "\n",
    "\n",
    "def testing():\n",
    "    # for rumors\n",
    "    test_data_rumors = TensorDataset(torch.from_numpy(np.load(preprocessed_data_paths['test_rumors_tweets path'])),\n",
    "                                     torch.from_numpy(np.load(preprocessed_data_paths['test_rumors_labels path'])))\n",
    "    test_loader_rumors = DataLoader(test_data_rumors, shuffle=False, batch_size=batch_size_test_rumors, drop_last=True)\n",
    "\n",
    "    # for stances\n",
    "    test_data_stances = TensorDataset(torch.from_numpy(np.load(preprocessed_data_paths['test_stances_tweets path'])),\n",
    "                                      torch.from_numpy(np.load(preprocessed_data_paths['test_stances_labels path'])))\n",
    "    test_loader_stances = DataLoader(test_data_stances, shuffle=False, batch_size=batch_size_test_stances, drop_last=True)\n",
    "\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # if we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    # create the model\n",
    "    model_multi_task = GRUMultiTask(input_length=input_length,\n",
    "                                    hidden_length_rumors=hidden_length_rumors,\n",
    "                                    hidden_length_stances=hidden_length_stances,\n",
    "                                    hidden_length_shared=hidden_length_shared,\n",
    "                                    loss_func='CrossEntropyLoss',\n",
    "                                    is_dropout=False\n",
    "                                    )\n",
    "    model_multi_task.to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Loading the model\n",
    "    model_multi_task.load_state_dict(torch.load('model/model_state_dict.pt'))\n",
    "\n",
    "    # Run the model\n",
    "    cnt_correct_test_rumors, cnt_correct_test_stances = validation_or_testing(model_multi_task, test_loader_rumors,\n",
    "                                                                                 test_loader_stances, criterion, device,\n",
    "                                                                                 operation='testing')\n",
    "    print('-----------------------------------------\\n')\n",
    "    validation_acc_rumors = cnt_correct_test_rumors / ((len(test_loader_rumors.dataset) / batch_size_test_rumors)\n",
    "                                                       * batch_size_test_rumors)\n",
    "    print(\"Test accuracy rumors: {:.3f}%\".format(validation_acc_rumors * 100))\n",
    "\n",
    "    validation_acc_stances = cnt_correct_test_stances / ((len(test_loader_stances.dataset) / batch_size_test_stances)\n",
    "                                                         * batch_size_test_stances)\n",
    "    print(\"Test accuracy stances: {:.3f}%\".format(validation_acc_stances * 100))\n",
    "\n",
    "testing()"
   ]
  },
  {
   "source": [
    "## Usage example\n",
    "**Lets take the following [*tweet*](https://figshare.com/articles/RumourEval_2019_data/8845580)**  \n",
    "\n",
    "**Tweet content:** #breaking Senior IOC member Dick Pound tells @usatodaysports the Tokyo 2020 Olympic Games will be postponed amid the coronavirus pandemic: \"It will come in stages. We will postpone this and begin to deal with all the ramifications of moving this, which are immense.\" \n",
    "@jaketapper  \n",
    "**Expected label:** True rumor\n",
    "\n",
    "**Reply tweet 1:** It’s the right thing. I feel badly but it’s not worth the risks  \n",
    "**Expected label:** Supporting\n",
    "\n",
    "**Reply tweet 2:** I truly believe this Olympic should be protected by international efforts. Future-oriented options.  \n",
    "**Expected label:** Supporting\n",
    "\n",
    "**Reply tweet 3:** Who now?  \n",
    "**Expected label:** Query\n",
    "\n",
    "**Reply tweet 4:** No. \"Senior IOC member Dick Pound.\" This is not real and I will not fall for this.  \n",
    "**Expected label:** Deny\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}